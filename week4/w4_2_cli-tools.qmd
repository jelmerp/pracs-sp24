---
title: "Running command-line tools with shell scripts"
subtitle: "Week 4 - shell scripts - part II"
pagetitle: "PRACS24: CLI tools in shell scripts"
author: Jelmer Poelstra
date: 2024-03-28
editor_options: 
  chunk_output_type: console
---

----------------------------------------------------------------------------------------------------

<br>

## Overview and setting up {-}

This session focuses on running programs, like various bioinformatics tools,
with command-line interfaces (CLIs), and on running them inside shell scripts.

The strategy that you'll learn is to
**write scripts that run a single program a single time**,
even if you need to run the program many times:
you'll loop over files _outside_ of that script.
This means you'll also need a higher-level "runner" script in which you save the
looping code and more.
We will talk about why this strategy makes sense, especially when you have a 
supercomputer at your disposal.

We'll start with a quick intro to FASTQ files and the FastQC program,
which will be our first example of a CLI tool.

#### Our practice data set

Our practice data set is from the paper
"*Two avian Plasmodium species trigger different transcriptional responses on their vector Culex pipiens*",
published last year in Molecular Ecology ([link](https://doi.org/10.1111/mec.17240)):

![](img/garrigos_paper.png){fig-align="center" width="80%"}

This paper uses RNA-seq data to study gene expression in *Culex pipiens* mosquitos
infected with malaria-causing *Plasmodium* protozoans --- specifically, it compares mosquitos according to:

- Infection status: *Plasmodium cathemerium* vs. *P. relictum* vs. control
- Time after infection: 24 h vs. 10 days vs. 21 days

However, our data has been **subset** to omit the 21-day samples and only keep 500,000
reads per FASTQ file. Our set of files consists of:

- 44 paired-end Illumina FASTQ files for 22 samples
- A Reference genome assembly in FASTA format and annotation in GTF format
- A metadata file in TSV format with sample IDs and treatment & time point info
- A README file describing the data set

#### Get your own copy of the data

```bash
# (Assuming you are in /fs/ess/PAS2700/users/$USER)
cd week04

cp -rv /fs/ess/PAS2700/share/garrigos_data .
```
```bash-out
â€˜/fs/ess/PAS2700/share/garrigos_dataâ€™ -> â€˜./garrigos_dataâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/metaâ€™ -> â€˜./garrigos_data/metaâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/meta/metadata.tsvâ€™ -> â€˜./garrigos_data/meta/metadata.tsvâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/refâ€™ -> â€˜./garrigos_data/refâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/ref/GCF_016801865.2.gtfâ€™ -> â€˜./garrigos_data/ref/GCF_016801865.2.gtfâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/ref/GCF_016801865.2.fnaâ€™ -> â€˜./garrigos_data/ref/GCF_016801865.2.fnaâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/fastqâ€™ -> â€˜./garrigos_data/fastqâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/fastq/ERR10802868_R2.fastq.gzâ€™ -> â€˜./garrigos_data/fastq/ERR10802868_R2.fastq.gzâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/fastq/ERR10802863_R1.fastq.gzâ€™ -> â€˜./garrigos_data/fastq/ERR10802863_R1.fastq.gzâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/fastq/ERR10802880_R2.fastq.gzâ€™ -> â€˜./garrigos_data/fastq/ERR10802880_R2.fastq.gzâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/fastq/ERR10802880_R1.fastq.gzâ€™ -> â€˜./garrigos_data/fastq/ERR10802880_R1.fastq.gzâ€™
â€˜/fs/ess/PAS2700/share/garrigos_data/fastq/ERR10802870_R1.fastq.gzâ€™ -> â€˜./garrigos_data/fastq/ERR10802870_R1.fastq.gzâ€™
# [...output truncated...]
```

<br>

## FASTQ files and FastQC

### The FASTQ format

FASTQ is a very common output format of high-throughput sequencing machines.
Like most genomic data files, these are plain text files.
Each sequence that is read by the sequencer (i.e., each "read") forms
**one FASTQ entry represented by four lines**.
The lines contain, respectively:

1.  A header that starts with `@` and e.g. uniquely identifies the read
2.  The nucleotide sequence itself
3.  A `+` (plus sign)
4.  One-character quality scores for each base in the sequence

![One entry (read) in a FASTQ file covers 4 lines. <br>The header line is annotated, with some of the more useful components highlighted in red. <br>For viewing purposes, this read (at only 56 bp) is shorter than what is typical.](img/fastq_header.png){fig-align="center" width="85%"}

The "Q" in FASTQ stands for "*quality*", to contrast this format with FASTA,
a more basic and generic sequence data format that does not include base quality scores.
FASTQ files have the extension `.fastq` or `.fq`,
but they are very commonly gzip-compressed, in which case their name ends in `.fastq.gz` or `.fq.gz`.

::: {.callout-note collapse="true"}
#### FASTQ quality scores *(Click to expand)*

The quality scores we saw in the read above represent an **estimate of the error probability of the base call**.
Specifically, they correspond to a numeric "Phred" quality score (`Q`),
which is a function of the estimated probability that a base call is erroneous (`P`):

> **Q = -10 \* log10(P)**

For some specific probabilities and their rough qualitative interpretations for Illumina data:

| Phred quality score | Error probability | Rough interpretation | ASCII character |
|------------------|------------------|------------------|------------------|
| **10**              | 1 in 10           | terrible             | `+`             |
| **20**              | 1 in 100          | bad                  | `5`             |
| **30**              | 1 in 1,000        | good                 | `?`             |
| **40**              | 1 in 10,000       | excellent            | `?`             |

This numeric quality score is represented in FASTQ files *not by the number itself*, but by a corresponding "ASCII character" (last column in the table). This allows for a single-character representation of each possible score â€” as a consequence, **each quality score character can conveniently correspond to (& line up with) a base character** in the read. (For your reference, [here is a complete lookup table](https://www.drive5.com/usearch/manual/quality_score.html) --- look at the top table, "BASE=33").
:::

<hr style="height:1pt; visibility:hidden;" />

### Our FASTQ files

Take a look at a file listing of your FASTQ files:

``` bash
ls -lh garrigos_data/fastq
```
``` bash-out
total 941M
-rw-r-----+ 1 jelmer PAS0471 21M Mar 21 09:38 ERR10802863_R1.fastq.gz
-rw-r-----+ 1 jelmer PAS0471 22M Mar 21 09:38 ERR10802863_R2.fastq.gz
-rw-r-----+ 1 jelmer PAS0471 21M Mar 21 09:38 ERR10802864_R1.fastq.gz
-rw-r-----+ 1 jelmer PAS0471 22M Mar 21 09:38 ERR10802864_R2.fastq.gz
-rw-r-----+ 1 jelmer PAS0471 22M Mar 21 09:38 ERR10802865_R1.fastq.gz
-rw-r-----+ 1 jelmer PAS0471 22M Mar 21 09:38 ERR10802865_R2.fastq.gz
-rw-r-----+ 1 jelmer PAS0471 21M Mar 21 09:38 ERR10802866_R1.fastq.gz
# [...output truncated...]
```

Note that:

- There are two files per sample: `_R1` (forward reads) and `_R2` (reverse reads).
- The files all have a `.gz` extension, indicating they have been _compressed_ with the gzip utility.
- The files are ~21-22 Mb in size --- considerably smaller than the original file sizes
  (around 1-2 Gb, which is typical) because they were subsampled.

<hr style="height:1pt; visibility:hidden;" />

### Viewing the contents of FASTQ files

Next, try to take a peak inside one of these FASTQ files.
Use `-n 8` with `head` to print the first 8 lines (2 reads):

``` bash
head -n 8 data/fastq/NW102AB_R1.fastq.gz
```
``` bash-out
ï¿½
Ô½Û’ï¿½8ï¿½Eï¿½ï¿½_1fï¿½"ï¿½QDï¿½Jï¿½ï¿½Dï¿½fs{ï¿½ï¿½ï¿½ï¿½Ykï¿½ï¿½ï¿½ï¿½dï¿½ï¿½*ï¿½ï¿½
|ï¿½ï¿½xï¿½ï¿½ï¿½lÞ´ï¿½jï¿½Nï¿½ï¿½ï¿½ï¿½ï¿½ï¿½?ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ù”ï¿½bUsï¿½Ngï¿½Ç¬ï¿½ï¿½ï¿½i;_ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½|<ï¿½vï¿½ï¿½ï¿½ï¿½3ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½|ï¿½ï¿½ï¿½Û§ï¿½ï¿½3ÄHyÆ•ï¿½bIÎŸDï¿½%ï¿½ï¿½ï¿½ï¿½Sr#~ï¿½ï¿½7ï¿½ï¿½Î½ï¿½ï¿½1yï¿½Ai,4
w\]"bï¿½#Qï¿½ï¿½ï¿½ï¿½8ï¿½ï¿½+[eï¿½3dï¿½4Hï¿½ï¿½ï¿½Ì’ï¿½lï¿½9LVMXï¿½ï¿½U*ï¿½Mï¿½ï¿½ï¿½ï¿½_?ï¿½ï¿½ï¿½\["ï¿½ï¿½7ï¿½s\<_ï¿½ï¿½ï¿½:ï¿½$ï¿½ï¿½ï¿½Nï¿½ï¿½vï¿½}^ï¿½ï¿½ï¿½ï¿½swï¿½|ï¿½n;<ï¿½<ï¿½oPï¿½ï¿½ï¿½ï¿½
iï¿½ï¿½kï¿½ï¿½qï¿½Ö°(Gï¿½Ï«ï¿½ï¿½Lï¿½^ï¿½ï¿½=ï¿½ï¿½<ï¿½ï¿½ï¿½Kï¿½ï¿½jï¿½_/ï¿½[Û­Vï¿½ns:ï¿½ï¿½Uï¿½ï¿½Gï¿½zï¿½ÝŽï¿½jï¿½ï¿½ï¿½ï¿½&ï¿½ï¿½~ï¿½Fï¿½ï¿½Ù¤ZNï¿½'ï¿½ï¿½r2z}ï¿½f\#ï¿½ï¿½:ï¿½9$ï¿½ï¿½ï¿½ï¿½ï¿½Hï¿½Ý‚ï¿½"ï¿½@Mï¿½ï¿½ï¿½ï¿½Hï¿½Cï¿½
ï¿½0ï¿½ppï¿½ï¿½ï¿½1ï¿½Oï¿½ï¿½Iï¿½Hï¿½Pë„ï¿½.È¢eï¿½ï¿½Qï¿½>ï¿½ï¿½ï¿½
ï¿½'ï¿½;@D8ï¿½ï¿½ï¿½#ï¿½ï¿½Stï¿½7kï¿½gï¿½ï¿½|ï¿½Aä‰»ï¿½ï¿½ï¿½_ï¿½ï¿½ï¿½dï¿½_cï¿½ï¿½ï¿½ï¿½ï¿½ï¿½a\ï¿½|ï¿½_ï¿½mnï¿½]ï¿½9Nï¿½ï¿½ï¿½ï¿½ï¿½ï¿½lï¿½Ù¢ZNï¿½cï¿½9uï¿½ï¿½ï¿½ï¿½ï¿½nï¿½ï¿½nï¿½`ï¿½ï¿½
"gÍºï¿½
    ï¿½ï¿½ï¿½Hï¿½?2@ï¿½FCï¿½S$nï¿½ï¿½ï¿½Ô’hï¿½       nÔ™jï¿½ï¿½æœ›ï¿½ï¿½f      ï¿½?N@ï¿½CzUlTï¿½&ï¿½hï¿½Pt!ï¿½r|ï¿½ï¿½9~)ï¿½ï¿½ï¿½eï¿½Aï¿½77ï¿½h{ï¿½ï¿½~ï¿½ï¿½     ï¿½ï¿½
# [...output truncated...]
```

<details><summary>Ouch! ðŸ˜³ What went wrong here? *(Click for the solution)*</summary>
We were directly presented with the contents of the *compressed* file, which isn't human-readable.
</details>

<hr style="height:1pt; visibility:hidden;" />

::: callout-note
#### No need to decompress
To get around the problem we just encountered with `head`,
we might be inclined to **uncompress** these files, which we could do with the **`gunzip` command**.
However, uncompressed files take up several times as much disk storage space as compressed ones.
Fortunately, we don't need to decompress them:

- Almost any bioinformatics tool will accept compressed FASTQ files.
- We can still view these files in compressed form, as shown below.
:::

Instead, we'll use the `less` command,
which automatically displays gzip-compressed files in human-readable form:

``` bash
less -S garrigos_data/fastq/ERR10802863_R1.fastq.gz
```
```bash-out
@ERR10802863.8435456 8435456 length=74
CAACGAATACATCATGTTTGCGAAACTACTCCTCCTCGCCTTGGTGGGGATCAGTACTGCGTACCAGTATGAGT
+
AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE
@ERR10802863.27637245 27637245 length=74
GCCACACTTTTGAAGAACAGCGTCATTGTTCTTAATTTTGTCGGCAACGCCTGCACGAGCCTTCCACGTAAGTT
+
AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEE<EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE
@ERR10802863.10009244 10009244 length=73
CTCGGCGTTAACTTCATCACGCAGATCATTCCGTTCCAGCAGCTGAAGCAAGACTACCGTCAGTACGAGATGA
+
AAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE
@ERR10802863.6604176 6604176 length=74
AACTACAAATCTTCCTGTGCCGTTTCCAGCAAGTACGTCGATACCTTCGATGGACGCAACTACGAGTACAACAT
+
AAAAAEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE
@ERR10802863.11918285 11918285 length=35
NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN
+
###################################
```

::: {.callout-tip}
#### The `-S` option to `less` suppresses line-wrapping: lines in the file will not be "wrapped" across multiple lines.
:::

<hr style="height:1pt; visibility:hidden;" />

::: exercise
#### {{< fa user-edit >}} **Exercise**: Explore the file with `less`

After running the command above, you should be viewing the file inside the `less` pager.

You can move around in the file in several ways: by scrolling with your mouse,
with up and down arrows, or, if you have them, <kbd>PgUp</kbd> and <kbd>PgDn</kbd> keys
(also, <kbd>u</kbd> will move up half a page and <kbd>d</kbd> down half a page).

Recall that you won't get your shell prompt back until you **press** <kbd>q</kbd> to quit `less`.
:::

<hr style="height:1pt; visibility:hidden;" />

### FastQC

FastQC is a ubiquitous tool for **quality control of FASTQ files**.
Running FastQC or a similar program is the first step in nearly any
high-throughput sequencing project.
FastQC is also a good introductory example of a tool with a command-line interface.

For each FASTQ file, FastQC outputs an **HTML file** that you can open in your
browser with about a dozen graphs showing different QC metrics.
The most important one is the *per-base quality score* graph:

![A FastQC per-base quality score graph for files with reasonably good quality reads.
The y-axis shows Phred quality scores (higher is better, see also the color-coding) and the x-axis shows the position along the read.](img/fastqc_good.png){fig-align="center" width="70%"}

<hr style="height:1pt; visibility:hidden;" />

## Running FastQC interactively

To run FastQC, we can use the command `fastqc`.

If you want to analyze one of your FASTQ files with default FastQC settings,
a complete FastQC command to do so would simply be `fastqc` followed by the name of the file:

``` bash
# (Don't run this)
fastqc garrigos_data/fastq/ERR10802863_R1.fastq.gz
```

However, an annoying FastQC default behavior is that it writes its output files
in the same dir that contains the input FASTQ files ---
this means mixing your raw data with your results, which we don't want!

To figure out how we can change that behavior,
first consider that many commands and bioinformatics tools alike have an
**option `-h` and/or `--help`** to print usage information to the screen.
Let's try that:

``` bash
fastqc -h
```
``` bash-out
bash: fastqc: command not found...
```

However, there is a wrinkle --- while FastQC is installed at OSC[^2], we have to first **"load it"**^[
We'll talk more about loading (and installing) software at OSC next week.]:

[^2]: For a full list of installed software at OSC: <https://www.osc.edu/resources/available_software/software_list>.

``` bash
module load fastqc/0.11.8
```

<hr style="height:1pt; visibility:hidden;" />

::: exercise
#### {{< fa user-edit >}} **Exercise**: FastQC help and output dir
Print FastQC's help info,
and figure out which option you can use to specify a custom output directory.

<details><summary>*Click for the solution*</summary>
Running `fastqc -h` or `fastqc --help` will work to show the help info.
You'll get quite a bit of output printed to screen,
including the snippet about output directories that is reproduced below:

``` bash
fastqc -h
```
``` bash-out
  -o --outdir     Create all output files in the specified output directory.
                    Please note that this directory must exist as the program
                    will not create it.  If this option is not set then the 
                    output file for each sequence file is created in the same
                    directory as the sequence file which was processed.
```

So, you can use `-o` or equivalently, `--outdir` to specify an output dir.
</details>
:::

<hr style="height:1pt; visibility:hidden;" />

With the added `--outdir` (or `-o`) option, let's try to run the following FastQC command:

``` bash
# We'll have to first create the outdir ourselves, in this case
mkdir -p results/fastqc

# Now we run FastQC
fastqc --outdir results/fastqc garrigos_data/fastq/ERR10802863_R1.fastq.gz
```
``` bash-out
Started analysis of ERR10802863_R1.fastq.gz
Approx 5% complete for ERR10802863_R1.fastq.gz
Approx 10% complete for ERR10802863_R1.fastq.gz
Approx 15% complete for ERR10802863_R1.fastq.gz
[...truncated...]
Analysis complete for ERR10802863_R1.fastq.gz
```

In the output dir we specified, we have a `.zip` file,
which contains tables with FastQC's data summaries,
and an `.html` (HTML) file, which contains the graphs:

``` bash
ls -lh results/fastqc
```
``` bash-out
total 512K
-rw-rw----+ 1 jelmer PAS0471 241K Mar 21 09:53 ERR10802863_R1_fastqc.html
-rw-rw----+ 1 jelmer PAS0471 256K Mar 21 09:53 ERR10802863_R1_fastqc.zip
```

::: callout-note
#### Specifying an output dir vs. output file(s)
FastQC allows us to specify the output directory, but not the output file names:
these will be automatically determined based on the input file name(s).
This kind of behavior is fairly common for bioinformatics programs,
since they will often produce multiple output files.
:::

<hr style="height:1pt; visibility:hidden;" />

::: exercise
#### {{< fa user-edit >}} **Exercise**: Another FastQC run

Run FastQC for the corresponding R2 FASTQ file.
Would you use the same output dir or a separate one?

<details><summary>*Click for the solution*</summary>

Yes, it makes sense to use the same output dir, since as you could see above,
the output file names have the input file identifiers in them.
As such, we don't need to worry about overwriting files,
and it will be more convenient to have all results in a single dir.

To run FastQC for the R2 (reverse-read) file:

``` bash
fastqc --outdir results/fastqc garrigos_data/fastq/ERR10802863_R2.fastq.gz
```
``` bash-out
Started analysis of ERR10802863_R2.fastq.gz
Approx 5% complete for ERR10802863_R2.fastq.gz
Approx 10% complete for ERR10802863_R2.fastq.gz
Approx 15% complete for ERR10802863_R2.fastq.gz
[...truncated...]
Analysis complete for ERR10802863_R2.fastq.gz
```

``` bash
ls -lh results/fastqc
```
``` bash-out
total 1008K
-rw-rw----+ 1 jelmer PAS0471 241K Mar 21 09:53 ERR10802863_R1_fastqc.html
-rw-rw----+ 1 jelmer PAS0471 256K Mar 21 09:53 ERR10802863_R1_fastqc.zip
-rw-rw----+ 1 jelmer PAS0471 234K Mar 21 09:55 ERR10802863_R2_fastqc.html
-rw-rw----+ 1 jelmer PAS0471 244K Mar 21 09:55 ERR10802863_R2_fastqc.zip
```

Now, we have four files: two for each of our preceding successful FastQC runs.

</details>
:::

<br>

## Running FastQC with a shell script

Instead of running FastQC interactively, we'll want to write a script that runs FastQC.
Specifically, our script will deliberately run FastQC on **only one FASTQ file**.

In bioinformatics, it is very common that you need to run a CLI tool many times,
because they should be independently run for each file or sample.
For such tools, an alternative approach would be to write the script such that it will
_process all files/samples in a single run_. That in turn can be accomplished by:

- Looping over files/samples inside the script.
- Simply passing many file names (or a glob with `*`) as arguments to a single
  run of the command --- note that this can be done with _some_ programs, including FastQC.

However, given that we have access to OSC's clusters, it will save
-potentially _a lot of_- running time when we submit a separate batch job for each FASTQ file.
And we make that possible by writing the script such that it will process only one file,
and by running this script many times while looping over all our FASTQ files.
For now, we'll practice with creating such a script and then running it interactively,
and next week, we will then take the next step and actually submit the script as batch jobs.

<hr style="height:1pt; visibility:hidden;" />

### Arguments to the script

Our approach of running the script for one FASTQ file at a time means that
our script needs to **accept an argument** (with in this case a FASTQ file name),
something we have practiced with in the previous session.
So instead of using a line like this in the script,
in which the FASTQ file name (`data/fastq/NW102AB_R1.fastq.gz`) is "hardcoded"...

```bash
fastqc --outdir results/fastqc garrigos_data/fastq/ERR10802863_R2.fastq.gz
```

...we would use a variable for the file name --- for example:

```bash
fastqc --outdir results/fastqc "$fastq_file"
```

And while we're at it, we may also want to use a variable for the output dir,
as that is another thing we may want to vary among runs of the program:

```bash
fastqc --outdir "$outdir" "$fastq_file"
```

Of course, these descriptively named variables don't appear out of thin air completely ---
we would need to pass arguments to the script when we run it,
and then copy the placeholder variables to ones with descriptive names inside the script:
  
```bash
# Copy the placeholder variables
fastq_file=$1
outdir=$2

# Run FastQC
fastqc --outdir "$outdir" "$fastq_file"
```

<hr style="height:1pt; visibility:hidden;" />

::: callout-note
#### Running the script
And such a script would be run for a single sample as follows:

```bash
# Syntax: 'bash <script-path> <argument1> <argument2>'
bash scripts/fastqc.sh garrigos_data/fastq/ERR10802863_R2.fastq.gz results/fastqc
```

And by looping over all files as follows:

```bash
# Run the script separately for each FASTQ file
for fastq_file in data/fastq/*fastq.gz; do
    bash scripts/fastqc.sh "$fastq_file" results/fastqc
done
```

However, note that the above would run FastQC sequentially for each file,
just like it would if the loop was in our script!
To get the promised running-time benefits,
we'd have to submit it as a batch job to OSC's Slurm queue.
We'll get into the details of doing this next week, but the main think we would need to do
is replacing `bash` by `sbatch`, which is the Slurm command to submit a batch job:

```bash
# Submit a Slurm batch job for each FASTQ file
for fastq_file in data/fastq/*fastq.gz; do
    sbatch scripts/fastqc.sh "$fastq_file" results/fastqc
done
```
:::

<hr style="height:1pt; visibility:hidden;" />

### Creating the full script

We should add a number of things to our partial script from above:

- The shebang line and strict Bash settings:

  ```bash
  #!/bin/bash
  
  # Strict Bash settings
  set -euo pipefail
  ```

- A line to load the relevant OSC software module:

  ```bash
  module load fastqc/0.11.8
  ```
  
- A line to create the output directory if it doesn't yet exist:

  ```bash
  mkdir -p "$outdir"
  ```

:::{.callout-tip collapse="true"}
## Refresher: the `-p` option to `mkdir` _(Click to expand)_

Using the `-p` option does two things at once,
and both are necessary for a foolproof inclusion of this command in a script:

- It will enable `mkdir` to create multiple levels of directories at once
  (i.e., to act _recursively_):
  by default, `mkdir` errors out if the parent directory/ies of the
  specified directory don't yet exist.

  ```bash
  mkdir newdir1/newdir2
  ```
  ```{.bash-out}
  mkdir: cannot create directory â€˜newdir1/newdir2â€™: No such file or directory
  ```

  ```bash
  # This successfully creates both directories
  mkdir -p newdir1/newdir2
  ```

- If the directory already exists, it won't do anything and won't return an error.
  Without this option, `mkdir` would return an error in this case,
  which would in turn lead the script to abort at that point with our `set` settings:
  
  ```bash
  mkdir newdir1/newdir2
  ```
  ```{.bash-out}
  mkdir: cannot create directory â€˜newdir1/newdir2â€™: File exists
  ```

  ```bash
  # This does nothing since the dirs already exist
  mkdir -p newdir1/newdir2
  ```
:::

Here is what our script looks like with those additions:

```bash
#!/bin/bash
  
# Strict Bash settings
set -euo pipefail

# Load the OSC module for FastQC
module load fastqc

# Copy the placeholder variables
fastq_file=$1
outdir=$2

# Create the output dir if needed
mkdir -p "$outdir"

# Run FastQC
fastqc --outdir="$outdir" "$fastq_file"
```

Notice that this script is very similar to our toy scripts from the previous sessions:
mostly standard ("boilerplate") code with
**just a single command to run our program of interest.**
Therefore, you can adopt this script as a template for scripts that run other
command-line programs, and will generally only need minor modifications!

<hr style="height:1pt; visibility:hidden;" />

### Report what's happening

It is often useful to have your scripts "report" or "log" what is going on.
For instance:

- At what date and time did we run this script 
- Which arguments were passed to the script
- What are the designated output dirs/files
- Perhaps even summaries of the output.

All of this can help with troubleshooting and record-keeping[^3].
Let's try this with our FastQC script:

[^3]: We'll see in the upcoming Slurm module that we when
      submit scripts to the OSC queue (rather than running them directly),
      the output of scripts that is normally printed to screen,
      will instead go to a sort of "log" file.
      So, your script's reporting will end up in this file.

```bash
#!/bin/bash
  
# Strict Bash settings
set -euo pipefail

# Load the OSC module for FastQC
module load fastqc

# Copy the placeholder variables
fastq_file=$1
outdir=$2

# Initial reporting
echo "# Starting script fastqc.ch"
date
echo "# Input FASTQ file:   $fastq_file"
echo "# Output dir:         $outdir"
echo

# Create the output dir if needed
mkdir -p "$outdir"

# Run FastQC
fastqc --outdir="$outdir" "$fastq_file"

# Final reporting
echo
echo "# Listing the output files:"
ls -lh "$outdir"
echo
echo "# Done with script fastqc.sh"
date
echo
```

A couple of notes about the lines that were added to the script above:

- We printed a "marker line" like `Done with script`, indicating that the end of the script was reached.
  This is handy due to our `set` settings:
  **seeing this line printed means that no errors were encountered**.
- Running `date` at the end of the script (as well as at the beginning)
  allows you to check for how long the script ran.
- Printing the input and output files (and the command-line arguments more generally)
  can be particularly useful for troubleshooting.
- We added some comment lines like "Initial logging" to make the script easier to read,
  and such comments can be made more extensive to really explain what is being done.
- The lines that just have `echo` without arguments will simply print a blank line,
  basically as a separator between sections.

:::{.callout-tip}
## `echo`, `echo`?
The extensive logging output (`echo` statements) may seem a bit overkill?
However, this can eventually be a time-saver because it makes it easier to spot
problems and helps with record-keeping.
This is especially true for long-running scripts,
or scripts that you often reuse and perhaps share with others.
:::

{{< fa user-edit >}} Open a new file in VS Code and save it as `fastqc.sh` within
your `scripts/` directory. Paste in the code above.

<br>

## A "runner" script

### What are runner scripts and why do we need them

Above, we created a `fastqc.sh` script,
which we want to run/submit many times with a `for` loop.
The loop code _could_ be directly typed in the terminal,
but it's better to save this in a file/script as well.

We will now create such a file,
which has the overall purpose of documenting the steps we took.
You can think of this file as akin to an analysis lab notebook^[
Or depending on how you use this exactly,
as your notebook entry that contains the final protocol you followed.].
Because it will contain shell code, we will save it as a shell script (`.sh`)
just like the script to run `fastqc.sh` and other individual analysis steps.

However, it is important to realize that **this script is conceptually different**
**from the scripts that run individual steps of your analysis.**
The latter are meant to be run/submitted in their entirety by the runner script,
whereas commands in the former typically have to be run one-by-one, i.e. interactively.
This kind of script is sometimes called a "runner" or "master" script.

::: {.callout-warning collapse="true"}
#### Why the runner script generally can't itself be run at once in its entirety _(Click to expand)_

First off, not that this applies only once we start submitting our scripts as batch jobs.

Once we've added multiple batch job steps,
and the input of a later step uses the output of an earlier step,
we won't be able to just _run_ the script as is.
**This is because the runner script would then submit jobs from different steps**
**all at once,**
**and that later step would start running before the earlier step has finished.**

For example, consider the following series of two steps,
in which the second step uses the output of the first step: 

```bash
# This script would create a genome "index" for STAR, that will be used in the next step
# ('my_genome.fa' = input genome FASTA, 'results/star_index' = output index dir)
sbatch scripts/star_index.sh my_genome.fa results/star_index

# This script would align a FASTQ file to the genome index created in the previous step
# ('results/star_index' = input index dir, 'sampleA.fastq.gz' = input FASTQ file,
# 'results/star_align' = output dir)
sbatch scripts/star_align.sh results/star_index sampleA.fastq.gz results/star_align 
```

If these two lines were included in your runner script,
and you would run that script in its entirety all at once,
the script in the second step would be submitted just a split-second after the
first one
(when using `sbatch`, you get your prompt back immediately -- there is no waiting).
As such, it would fail because of the missing output from the first step.

It _is_ possible to make `sbatch` batch jobs wait for earlier steps to finish
(e.g. with the `--dependency` option), but this quickly gets tricky.
If you want to create a workflow/pipeline that can run from start to finish in
an automated way, 
you should consider using a workflow management system
like [Snakemake](https://snakemake.readthedocs.io/en/stable/) or
[NextFlow](https://www.nextflow.io/) --- we will talk about Nextflow in week 6!
:::

To summarize, we'll **separate our code into two hierarchical levels of scripts**:

- The scripts that run _individual steps of your analysis_, like `fastqc.sh`.
- An _overarching "runner" script_ that orchestrates the batch job submission
  of these individual steps.

To make this division clearer, we'll also save these scripts in separate directories:

- `scripts` for the analysis scripts.
- `run` for the runner script.

<hr style="height:1pt; visibility:hidden;" />

::: {.callout-tip}
#### Keep the scripts for individual steps simple
It is a good idea to keep the shell scripts you will submit (e.g., `fastqc.sh`) simple
_in the sense that they should generally just run one program_,
and not a sequence of programs.

Once you get the hang of writing these scripts,
it may seem appealing to string a series of programs/steps together in a single script,
so that it's easier to rerun everything at once ---
but in practice, that will often end up leading to more difficulties than convenience.
If you do want to develop a workflow that can be easily run and rerun
from start to finish,
you should learn a workflow management system like Snakemake or Nextflow ---
we will talk about Nextflow in week 6.
:::

<hr style="height:1pt; visibility:hidden;" />

### Starting our runner script

Open a new text file, and save it as **`run.sh`**^[
We won't save it in a separate dir here as our other script are not in a dedicated dir either.
]
In this script, add the code that runs our `fastqc.sh` script for each FASTQ file,
and then run it:

```bash
# Run FastQC for each FASTQ file
for fastq_file in garrigos_data/fastq/*fastq.gz; do
    bash scripts/fastqc.sh "$fastq_file" results/fastqc
done
```
```bash-out
# Starting script fastqc.ch
Thu Mar 21 10:06:46 EDT 2024
# Input FASTQ file:   garrigos_data/fastq/ERR10802863_R1.fastq.gz
# Output dir:         results/fastqc

Started analysis of ERR10802863_R1.fastq.gz
Approx 5% complete for ERR10802863_R1.fastq.gz
Approx 10% complete for ERR10802863_R1.fastq.gz
Approx 15% complete for ERR10802863_R1.fastq.gz
Approx 20% complete for ERR10802863_R1.fastq.gz
Approx 25% complete for ERR10802863_R1.fastq.gz
Approx 30% complete for ERR10802863_R1.fastq.gz
Approx 35% complete for ERR10802863_R1.fastq.gz
Approx 40% complete for ERR10802863_R1.fastq.gz
Approx 45% complete for ERR10802863_R1.fastq.gz
Approx 50% complete for ERR10802863_R1.fastq.gz
Approx 55% complete for ERR10802863_R1.fastq.gz
Approx 60% complete for ERR10802863_R1.fastq.gz
Approx 65% complete for ERR10802863_R1.fastq.gz
Approx 70% complete for ERR10802863_R1.fastq.gz
Approx 75% complete for ERR10802863_R1.fastq.gz
Approx 80% complete for ERR10802863_R1.fastq.gz
Approx 85% complete for ERR10802863_R1.fastq.gz
Approx 90% complete for ERR10802863_R1.fastq.gz
Approx 95% complete for ERR10802863_R1.fastq.gz
Approx 100% complete for ERR10802863_R1.fastq.gz
Analysis complete for ERR10802863_R1.fastq.gz

# Listing the output files:
total 496K
-rw-rw----+ 1 jelmer PAS0471 241K Mar 21 10:06 ERR10802863_R1_fastqc.html
-rw-rw----+ 1 jelmer PAS0471 256K Mar 21 10:06 ERR10802863_R1_fastqc.zip
-rw-rw----+ 1 jelmer PAS0471 234K Mar 21 09:55 ERR10802863_R2_fastqc.html
-rw-rw----+ 1 jelmer PAS0471 244K Mar 21 09:55 ERR10802863_R2_fastqc.zip

# Done with script fastqc.sh
Thu Mar 21 10:06:51 EDT 2024

# Starting script fastqc.ch
Thu Mar 21 10:06:51 EDT 2024
# Input FASTQ file:   garrigos_data/fastq/ERR10802863_R2.fastq.gz
# Output dir:         results/fastqc

Started analysis of ERR10802863_R2.fastq.gz
Approx 5% complete for ERR10802863_R2.fastq.gz
Approx 10% complete for ERR10802863_R2.fastq.gz
# [...output truncated...]
```

<br>

## Looping over samples rather than files 

In some cases, we can't simply loop over all files the way we have so far.
For example, in many tools that process paired-end FASTQ files,
the corresponding R1 and R2 files for each sample must be processed together.
That is, we don't run the tool separately for each FASTQ file,
but separately for each sample i.e. each _pair_ of FASTQ files.

How can we loop over pairs of FASTQ files instead? There are two main ways:

- Create a list of **sample IDs**, loop over these IDs, and find the pair of
  FASTQ files with matching names.
- Loop over the **R1 files only** and then infer the name of the corresponding
  R2 file within the loop. This is generally straightforward because the file names
  should be identical other than the read-direction identifier (`R1`/`R2`).

Below, we will use the second method --- but first, we'll recap/learn a few prerequisites.

<hr style="height:1pt; visibility:hidden;" />

### Recap of `basename`, and `dirname`

Running the `basename` command on a filename will strip any directories in its name:
  
```sh
basename garrigos_data/fastq/ERR10802863_R1.fastq.gz
```
```bash-out
ERR10802863_R1.fastq.gz
```

You can also provide any arbitrary *suffix to strip* from the file name:

```sh
basename garrigos_data/fastq/ERR10802863_R1.fastq.gz .fastq.gz
```
```bash-out
ERR10802863_R1
```

If you instead want the _directory_ part of the path, use the `dirname` command:

```sh
dirname garrigos_data/fastq/ERR10802863_R1.fastq.gz
```
```bash-out
garrigos_data/fastq
```

<hr style="height:1pt; visibility:hidden;" />

### Parameter expansion

You can use so-called "parameter expansion", with parameter basically being another
word for variable, to search-and-replace text in your variable's values.
For example:

- Assign a short DNA sequence to a variable:

  ```bash
  dna_seq="AAGTTCAT"
  echo "$dna_seq"
  ```
  ```bash-out
  AAGTTCAT
  ```

- Use parameter expansion to replace all `T`s with `U` to convert the DNA to RNA:

  ```bash
  echo "${dna_seq//T/U}"
  ```
  ```bash-out
  AAGUUCAT
  ```

- You can of course also assign the result of the expansion back to a variable:

  ```bash
  rna_seq="${dna_seq//T/U}"
  echo "$rna_seq"
  ```
  ```bash-out
  AAGUUCAT
  ```

So, the syntax for this type of parameter expansion is `{var_name//<search>/replace}`:

1. Reference the variable, using the long notation (`${var_name}` above)
2. After the first two forward slashes, enter the search pattern: (`T`)
3. After another forward slash, enter the replacement: (`U`).

If you needed to replace at most one of the search patterns, a single backslash
after the variable name would suffice: `{var_name/<search>/replace}`.

<hr style="height:1pt; visibility:hidden;" />

::: exercise
#### {{< fa user-edit >}} Exercise: Get the R2 file name with parameter expansion
File names of corresponding R1 and R2 FASTQ files should be identical other than
the marker indicating the read direction,
which is typically `R1`/`R2` (and in some cases just `1` and `2`).

Assign the file name `garrigos_data/fastq/ERR10802863_R1.fastq.gz` to a variable
and use parameter expansion to get the name of the corresponding R2 file name.
Also save the R2 file name in a variable.

<details><summary>Solutions</summary>

```bash
fastq_R1=garrigos_data/fastq/ERR10802863_R1.fastq.gz
fastq_R2=${fastq_R1/_R1/_R2}
```

Above, e.g. `${fastq_R1/R1/R2}`, that is without underscores, would have also worked.
But note that it's generally good to avoid unwanted search-pattern matches by making the
search string as specific as possible.
So perhaps `${fastq_R1/_R1.fastq.gz/_R2.fastq.gz}` would have been even better.

Test that it worked:

```bash
echo "$fastq_R2"
```
```bash-out
garrigos_data/fastq/ERR10802863_R2.fastq.gz
```
</details>
:::

<hr style="height:1pt; visibility:hidden;" />

### A per-sample loop

We will now create a loop that:

- Loops over R1 FASTQ files only, and then infers the corresponding R2 file name.
- Defines output file names that are the same as the input file names but in a different dir.

To stay focused just on the shell syntax here,
we won't include code to run an actual bioinformatics tool
(you'll do that in [this week's exercises](w4_exercises.qmd)),
but will use a fictional example:

```bash
# Loop over the R1 files - our glob is `*_R1.fastq.gz` to only select R1 files
for R1_in in garrigos_data/fastq/*_R1.fastq.gz; do
    # Get the R2 file name with parameter expansion
    R2_in=${R1_in/_R1/_R2}
    
    # Define the output files (assume that a variable $outdir exists)
    R1_out="$outdir"/$(basename "$R1_in")
    R2_out="$outdir"/$(basename "$R2_in")
    
    # Report
    echo "Input files: $R1_in $R2_in"
    echo "Output files: $R1_out $R2_out"
    
    # Use the imaginary program 'trimmer' with options --in1/--in2 for the R1/R2 input files,
    # and --out1/--out2 for the R1/R2 output files:
    trimmer --in1 "$R1_in" --in2 "$R2_in" --out1 "$R1_out" --out2 "$R2_out"
done
```

<hr style="height:1pt; visibility:hidden;" />

### Converting to the single-sample script format

But wait! Aren't we supposed to write a script that only processes one sample at
a time, and then run/submit that script with a loop?
That's right, so now that we know what to do, let's switch to that setup.

Create a new script `scripts/trim_mock.sh` and paste the following code into it:

```bash
#!/bin/bash
  
# Strict Bash settings
set -euo pipefail

# Copy the placeholder variables
R1_in=$1
outdir=$2

# Create the output dir if needed
mkdir -p "$outdir"

# Infer the R2_in file name
R2_in=${R1_in/_R1/_R2}
    
# Define the output file names
R1_out="$outdir"/$(basename "$R1_in")
R2_out="$outdir"/$(basename "$R2_in")

# Initial reporting
echo "# Starting script trim_mock.sh"
date
echo "# Input R1 file:       $R1_in"
echo "# Input R2 file:       $R2_in"
echo "# Output R1 file:      $R1_out"
echo "# Output R2 file:      $R2_out"
echo

# Mock-run the tool: I preface the command with 'echo' so this will just report
# and not try to run a program that doesn't exist
echo trimmer --in1 "$R1_in" --in2 "$R2_in" --out1 "$R1_out" --out2 "$R2_out"

# I will also create the output files so the final reporting doesn't error out
touch "$R1_out" "$R2_out"

# Final reporting
echo
echo "# Listing the output files:"
ls -lh "$R1_out" "$R2_out"
echo
echo "# Done with script trim_mock.sh"
date
echo
```

Now, add the following code to our `run.sh` script, and run that:

```bash
# Run the trim_mock.sh script for each sample
for R1_in in garrigos_data/fastq/*_R1.fastq.gz; do
    bash scripts/trim_mock.sh "$R1_in" results/trim_mock
done
```
```bash-out
# Starting script trim_mock.sh
Thu Mar 21 10:12:17 EDT 2024
# Input R1 file:       garrigos_data/fastq/ERR10802863_R1.fastq.gz
# Input R2 file:       garrigos_data/fastq/ERR10802863_R2.fastq.gz
# Output R1 file:      results/trim_mock/ERR10802863_R1.fastq.gz
# Output R2 file:      results/trim_mock/ERR10802863_R2.fastq.gz

trimmer --in1 garrigos_data/fastq/ERR10802863_R1.fastq.gz --in2 garrigos_data/fastq/ERR10802863_R2.fastq.gz --out1 results/trim_mock/ERR10802863_R1.fastq.gz --out2 results/trim_mock/ERR10802863_R2.fastq.gz

# Listing the output files:
-rw-rw----+ 1 jelmer PAS0471 0 Mar 21 10:12 results/trim_mock/ERR10802863_R1.fastq.gz
-rw-rw----+ 1 jelmer PAS0471 0 Mar 21 10:12 results/trim_mock/ERR10802863_R2.fastq.gz

# Done with script trim_mock.sh
Thu Mar 21 10:12:17 EDT 2024

# Starting script trim_mock.sh
Thu Mar 21 10:12:17 EDT 2024
# Input R1 file:       garrigos_data/fastq/ERR10802864_R1.fastq.gz
# Input R2 file:       garrigos_data/fastq/ERR10802864_R2.fastq.gz
# Output R1 file:      results/trim_mock/ERR10802864_R1.fastq.gz
# Output R2 file:      results/trim_mock/ERR10802864_R2.fastq.gz
# [...output truncated...]
```

Check the files in the output dir:

```bash
ls -lh results/trim_mock
```
```bash-out
total 0
-rw-rw----+ 1 jelmer PAS0471 0 Mar 21 10:12 ERR10802863_R1.fastq.gz
-rw-rw----+ 1 jelmer PAS0471 0 Mar 21 10:12 ERR10802863_R2.fastq.gz
-rw-rw----+ 1 jelmer PAS0471 0 Mar 21 10:12 ERR10802864_R1.fastq.gz
-rw-rw----+ 1 jelmer PAS0471 0 Mar 21 10:12 ERR10802864_R2.fastq.gz
-rw-rw----+ 1 jelmer PAS0471 0 Mar 21 10:12 ERR10802865_R1.fastq.gz
-rw-rw----+ 1 jelmer PAS0471 0 Mar 21 10:12 ERR10802865_R2.fastq.gz
-rw-rw----+ 1 jelmer PAS0471 0 Mar 21 10:12 ERR10802866_R1.fastq.gz
# [...output truncated...]
```

<br>
