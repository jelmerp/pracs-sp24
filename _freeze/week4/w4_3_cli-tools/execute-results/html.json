{
  "hash": "1972ceeb4b571a68e2712a4bb8996e38",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Running command-line programs with shell scripts\"\nsubtitle: \"Week 4 - part III\"\npagetitle: \"PRACS24: CLI tools in shell script\"\nauthor: Jelmer Poelstra\ndate: 2024-03-28\n---\n\n----------------------------------------------------------------------------------------------------\n\n<br>\n\nIn this session, ...\n\n<br>\n\n\n## FASTQ files and FastQC\n\n### The FASTQ format\n\nFASTQ is a very common output format of high-throughput sequencing machines.\nLike most genomic data files, these are plain text files.\nEach sequence that is read by the sequencer (i.e., each \"read\") forms\n**one FASTQ entry represented by four lines**.\nThe lines contain, respectively:\n\n1.  A **header** that starts with `@` and e.g. uniquely identifies the read\n2.  The **sequence** itself\n3.  A **`+`** (plus sign)\n4.  One-character **quality scores** for each base in the sequence\n\n![One entry (read) in a FASTQ file covers 4 lines. <br>The header line is annotated, with some of the more useful components highlighted in red. <br>For viewing purposes, this read (at only 56 bp) is shorter than what is typical.](img/fastq_header.png){fig-align=\"center\" width=\"85%\"}\n\nThe \"Q\" in FASTQ stands for \"*quality*\", to contrast this format with FASTA,\na more basic and generic sequence data format that does not include base quality scores.\nFASTQ files have the extension `.fastq` or `.fq`,\nbut they are very commonly gzip-compressed, in which case their name ends in `.fastq.gz` or `.fq.gz`.\n\n::: {.callout-note collapse=\"true\"}\n#### FASTQ quality scores *(Click to expand)*\n\nThe quality scores we saw in the read above represent an **estimate of the error probability of the base call**.\nSpecifically, they correspond to a numeric \"Phred\" quality score (`Q`),\nwhich is a function of the estimated probability that a base call is erroneous (`P`):\n\n> **Q = -10 \\* log10(P)**\n\nFor some specific probabilities and their rough qualitative interpretations for Illumina data:\n\n| Phred quality score | Error probability | Rough interpretation | ASCII character |\n|------------------|------------------|------------------|------------------|\n| **10**              | 1 in 10           | terrible             | `+`             |\n| **20**              | 1 in 100          | bad                  | `5`             |\n| **30**              | 1 in 1,000        | good                 | `?`             |\n| **40**              | 1 in 10,000       | excellent            | `?`             |\n\nThis numeric quality score is represented in FASTQ files *not by the number itself*, but by a corresponding \"ASCII character\" (last column in the table). This allows for a single-character representation of each possible score â€” as a consequence, **each quality score character can conveniently correspond to (& line up with) a base character** in the read. (For your reference, [here is a complete lookup table](https://www.drive5.com/usearch/manual/quality_score.html) --- look at the top table, \"BASE=33\").\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Our FASTQ files\n\nOur FASTQ files contain reads from 2x300 bp (i.e. paired-end with 300 bp\nforward and 300 bp reverse reads) sequencing on an Illumina MiSeq machine.\nLet's take a look at our list of FASTQ files:\n\n``` bash\nls -lh data/fastq\n```\n``` bash-out\ntotal 150M\n-rw-r-----+ 1 jelmer PAS0471 2.0M Mar  1 17:09 NW102AB_R1.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 2.6M Mar  1 17:09 NW102AB_R2.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 2.3M Mar  1 17:09 NW102C_R1.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 3.0M Mar  1 17:09 NW102C_R2.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 1.9M Mar  1 17:09 NW103AB_R1.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 2.6M Mar  1 17:09 NW103AB_R2.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 2.3M Mar  1 17:09 NW103C_R1.fastq.gz\n-rw-r-----+ 1 jelmer PAS0471 3.1M Mar  1 17:09 NW103C_R2.fastq.gz\n# [...output truncated...]\n```\n\nNote in the file listing above that:\n\n-   There are two files per sample: `_R1` (forward reads) and `_R2` (reverse reads).\n    This indicates that we have data from **paired-end reads**,\n    as is customary when doing amplicon metabarcoding.\n-   The files all have a `.gz` extension, indicating they have been _compressed_ with the gzip utility.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Viewing the contents of FASTQ files\n\nNext, we'll take a peak inside one of these FASTQ files.\nWe can use `-n 8` with `head` to make it print the first 8 lines (= 2 reads of the file):\n\n``` bash\nhead -n 8 data/fastq/NW102AB_R1.fastq.gz\n```\n``` bash-out\nï¿½\nÔ½Û’ï¿½8ï¿½Eï¿½ï¿½_1fï¿½\"ï¿½QDï¿½Jï¿½ï¿½Dï¿½fs{ï¿½ï¿½ï¿½ï¿½Ykï¿½ï¿½ï¿½ï¿½dï¿½ï¿½*ï¿½ï¿½\n|ï¿½ï¿½xï¿½ï¿½ï¿½lÞ´ï¿½jï¿½Nï¿½ï¿½ï¿½ï¿½ï¿½ï¿½?ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ù”ï¿½bUsï¿½Ngï¿½Ç¬ï¿½ï¿½ï¿½i;_ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½|<ï¿½vï¿½ï¿½ï¿½ï¿½3ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½|ï¿½ï¿½ï¿½Û§ï¿½ï¿½3ÄHyÆ•ï¿½bIÎŸDï¿½%ï¿½ï¿½ï¿½ï¿½Sr#~ï¿½ï¿½7ï¿½ï¿½Î½ï¿½ï¿½1yï¿½Ai,4\nw\\]\"bï¿½#Qï¿½ï¿½ï¿½ï¿½8ï¿½ï¿½+[eï¿½3dï¿½4Hï¿½ï¿½ï¿½Ì’ï¿½lï¿½9LVMXï¿½ï¿½U*ï¿½Mï¿½ï¿½ï¿½ï¿½_?ï¿½ï¿½ï¿½\\[\"ï¿½ï¿½7ï¿½s\\<_ï¿½ï¿½ï¿½:ï¿½$ï¿½ï¿½ï¿½Nï¿½ï¿½vï¿½}^ï¿½ï¿½ï¿½ï¿½swï¿½|ï¿½n;<ï¿½<ï¿½oPï¿½ï¿½ï¿½ï¿½\niï¿½ï¿½kï¿½ï¿½qï¿½Ö°(Gï¿½Ï«ï¿½ï¿½Lï¿½^ï¿½ï¿½=ï¿½ï¿½<ï¿½ï¿½ï¿½Kï¿½ï¿½jï¿½_/ï¿½[Û­Vï¿½ns:ï¿½ï¿½Uï¿½ï¿½Gï¿½zï¿½ÝŽï¿½jï¿½ï¿½ï¿½ï¿½&ï¿½ï¿½~ï¿½Fï¿½ï¿½Ù¤ZNï¿½'ï¿½ï¿½r2z}ï¿½f\\#ï¿½ï¿½:ï¿½9$ï¿½ï¿½ï¿½ï¿½ï¿½Hï¿½Ý‚ï¿½\"ï¿½@Mï¿½ï¿½ï¿½ï¿½Hï¿½Cï¿½\nï¿½0ï¿½ppï¿½ï¿½ï¿½1ï¿½Oï¿½ï¿½Iï¿½Hï¿½Pë„ï¿½.È¢eï¿½ï¿½Qï¿½>ï¿½ï¿½ï¿½\nï¿½'ï¿½;@D8ï¿½ï¿½ï¿½#ï¿½ï¿½Stï¿½7kï¿½gï¿½ï¿½|ï¿½Aä‰»ï¿½ï¿½ï¿½_ï¿½ï¿½ï¿½dï¿½_cï¿½ï¿½ï¿½ï¿½ï¿½ï¿½a\\ï¿½|ï¿½_ï¿½mnï¿½]ï¿½9Nï¿½ï¿½ï¿½ï¿½ï¿½ï¿½lï¿½Ù¢ZNï¿½cï¿½9uï¿½ï¿½ï¿½ï¿½ï¿½nï¿½ï¿½nï¿½`ï¿½ï¿½\n\"gÍºï¿½\n    ï¿½ï¿½ï¿½Hï¿½?2@ï¿½FCï¿½S$nï¿½ï¿½ï¿½Ô’hï¿½       nÔ™jï¿½ï¿½æœ›ï¿½ï¿½f      ï¿½?N@ï¿½CzUlTï¿½&ï¿½hï¿½Pt!ï¿½r|ï¿½ï¿½9~)ï¿½ï¿½ï¿½eï¿½Aï¿½77ï¿½h{ï¿½ï¿½~ï¿½ï¿½     ï¿½ï¿½\n# [...output truncated...]\n```\n\n<details><summary>Ouch! ðŸ˜³ What went wrong here? *(Click for the solution)*</summary>\nWhat happened here is that we are directly seeing the contents of the *compressed* file,\nwhich is simply not human-readable.\n</details>\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: callout-note\n#### No need to decompress\nTo get around the problem we just encountered with `head`,\nwe might be inclined to **uncompress** these files, which we could do with the **`gunzip` command**.\nHowever, uncompressed files take up several times as much disk storage space as compressed ones.\nFortunately, we don't need to decompress them:\n\n- Almost any bioinformatics tool will accept compressed FASTQ files.\n- We can still view these files in compressed form, as shown below.\n:::\n\nInstead, we'll use the `less` command,\nwhich automatically displays gzip-compressed files in human-readable form:\n\n``` bash\nless -S data/fastq/NW102AB_R1.fastq.gz\n```\n```bash-out\n@M02815:77:000000000-KPK85:1:2101:3678:10660 1:N:0:CCTAAGAC+TTCTAGCT\nCGAGCAATCCACTCGAGTGCCAGCAGCCGCAGTAATACGGAGGGTGCGAGCGTTGTCCGGAATCACTGGGCGTAAAGGGCGCGTAGGCGGCGCGGATAGTCGGCGGTGAAAGCCCGGAGCTCAACTCCGGGTCGGCCGTCGATACTTCCGGGCTTGAGCACTGTAGAGGCAGATGGAATTCCGGGTGTAGCGGTGGAATGCGTAGAGATCCGGAAGAACACCGGTGGCGAAGGCGGTCTGCTGGGCAGTTGCTGACGCTGATGCGCGACAGCGTGGGGAGCAAACAGGATTAGATACC\n+\nCCCCCGGGGGGGGGGGGGGFGGGGGGGGGG+CFGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGDGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGDGGGGGGGGGGGGGGGGGGGGGGGGGGGGGFGGGGGGGGGGGGGGGGEGGGGGGGGGGGGGGGGGGGGDGGGGGGGGGGGGGGFGGFGFFFFEBFFGFFFDGFGFGBFGFGFGFFFF6?FFFGBF?FBFFF\n@M02815:77:000000000-KPK85:1:2108:2535:14400 1:N:0:CCTAAGAC+TTCTAGCT\nCGAGCAATCCACTCGAGTGTCAGCCGCCGCGGTAATACAGAGGTCCCGAGCGTTGTTCGGATTCATTGGGCGTAAAGGGTGCGTAGGCGGCGGGGAAAGTCTGATGTGAAATCCTGGGGCTCAACCCTGGAACTGCATTGGATACTTCCTTGCTAGAGTACTGGAGAGGAAACTGGAATTTACGGTGTAGCAGTGAAATGCGTAGAGATCGTAAGGAAGACCAGTGGCGAAGGCGAGTTTCTGGACAGTTACTGACGCTGAGGCACGAAGGCCAGGGGAGCAAACGGGATTAGATACC\n+\nCCCCCCGFGFGGGC-FFFGFGFFGGDFFGGGGGECGEGGAEGGGGGGGFGGDGG7CFFGGDCCFGGFCF8FGGGGGGCEGDGGGGGCGGGGGGDEGGGGBFGGDFGGGDG<DFGGGGCEGGGD:FFGGGGFFGFGGFFFFGGGFGGCFGGFGGGGG9CGCGGGG7FGGC:FFGGGGGFGG<?FCGGGGGGGGGGG9CG<ACC?EG5CFGGGGF8CCCC:C@FGCFGGGGGC58=EEG8??77:9@:<3A>7AGFGGGGC?DFC?5<5>>BGGGFGGGGG>4?C42::3:DG=><<*)*\n```\n\n::: {.callout-tip}\n#### The `-S` option to `less` suppresses line-wrapping: lines in the file will not be \"wrapped\" across multiple lines.\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: exercise\n#### {{< fa user-edit >}} **Exercise**: Explore the file with `less`\n\nAfter running the command above, you should be viewing the file inside the `less` pager.\n\nYou can move around in the file in several ways: by scrolling with your mouse,\nwith up and down arrows, or, if you have them, <kbd>PgUp</kbd> and <kbd>PgDn</kbd> keys\n(also, <kbd>u</kbd> will move up half a page and <kbd>d</kbd> down half a page).\n\nRecall that you won't get your shell prompt back until you **press** <kbd>q</kbd> to quit `less`.\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### FastQC\n\nFastQC is a ubiquitous tool for **quality control of FASTQ files**.\nRunning FastQC or a similar program is the first step in nearly any\nhigh-throughput sequencing project.\nFastQC is also a good introductory example of a tool with a command-line interface.\n\nFor each FASTQ file, FastQC outputs an **HTML file** that you can open in your\nbrowser with about a dozen graphs showing different QC metrics.\nThe most important one is the *per-base quality score* graph:\n\n![A FastQC per-base quality score graph for files with reasonably good quality reads.\nThe y-axis shows Phred quality scores (higher is better, see also the color-coding) and the x-axis shows the position along the read.](img/fastqc_good.png){fig-align=\"center\" width=\"70%\"}\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n## Running FastQC interactively\n\nTo run FastQC, we can use the command `fastqc`.\n\nIf you want to analyze one of your FASTQ files with default FastQC settings,\na complete FastQC command to do so would simply be `fastqc` followed by the name of the file:\n\n``` bash\n# (Don't run this)\nfastqc data/fastq/NW102AB_R1.fastq.gz\n```\n\nHowever, an annoying FastQC default behavior is that it writes its output files\nin the same dir that contains the input FASTQ files ---\nthis means mixing your raw data with your results, which we don't want!\n\nTo figure out how we can change that behavior,\nfirst consider that many commands and bioinformatics tools alike have an\n**option `-h` and/or `--help`** to print usage information to the screen.\nLet's try that:\n\n``` bash\nfastqc -h\n```\n``` bash-out\nbash: fastqc: command not found...\n```\n\nHowever, there is a wrinkle --- while FastQC is installed at OSC[^2], we have to first **\"load it\"**:\n\n[^2]: For a full list of installed software at OSC: <https://www.osc.edu/resources/available_software/software_list>\n\n``` bash\nmodule load fastqc/0.11.8\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: exercise\n#### {{< fa user-edit >}} **Exercise**: FastQC help and output dir\nPrint FastQC's help info,\nand figure out which option you can use to specify a custom output directory.\n\n<details><summary>*Click for the solution*</summary>\nRunning `fastqc -h` or `fastqc --help` will work to show the help info.\nYou'll get quite a bit of output printed to screen,\nincluding the snippet about output directories that is reproduced below:\n\n``` bash\nfastqc -h\n```\n``` bash-out\n  -o --outdir     Create all output files in the specified output directory.\n                    Please note that this directory must exist as the program\n                    will not create it.  If this option is not set then the \n                    output file for each sequence file is created in the same\n                    directory as the sequence file which was processed.\n```\n\nSo, you can use `-o` or equivalently, `--outdir` to specify an output dir.\n</details>\n:::\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\nWith the added `--outdir` (or `-o`) option, let's try to run the following FastQC command:\n\n``` bash\n# We'll have to first create the outdir ourselves, in this case\nmkdir -p results/fastqc\n\n# Now we run FastQC\nfastqc --outdir results/fastqc data/fastq/NW102AB_R1.fastq.gz\n```\n``` bash-out\napplication/gzip\nStarted analysis of NW102AB_R1.fastq.gz\nApprox 5% complete for NW102AB_R1.fastq.gz\nApprox 10% complete for NW102AB_R1.fastq.gz\nApprox 15% complete for NW102AB_R1.fastq.gz\n[...truncated...]\nAnalysis complete for NW102AB_R1.fastq.gz\n```\n\nSuccess!! ðŸŽ‰\n\n::: callout-note\n#### Specifying an output dir vs. output file(s)\nFastQC allows us to specify the output directory, but not the output file names:\nthese will be automatically determined based on the input file name(s).\nThis kind of behavior is fairly common for bioinformatics programs,\nsince they will often produce multiple output files.\n:::\n\nIn the output dir we specified, we have a `.zip` file,\nwhich contains tables with FastQC's data summaries,\nand an `.html` (HTML) file, which contains the graphs:\n\n``` bash\nls -lh results/fastqc\n```\n``` bash-out\ntotal 1.2M\n-rw-r--r-- 1 jelmer PAS0471 241K Mar 13 14:50 NW102AB_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 256K Mar 13 14:50 NW102AB_R1_fastqc.zip\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n::: exercise\n#### {{< fa user-edit >}} **Exercise**: Another FastQC run\n\nRun FastQC for the corresponding R2 FASTQ file.\nWould you use the same output dir or a separate one?\n\n<details><summary>*Click for the solution*</summary>\n\nYes, it makes sense to use the same output dir, since as you could see above,\nthe output file names have the input file identifiers in them.\nAs such, we don't need to worry about overwriting files,\nand it will be more convenient to have all results in a single dir.\n\nTo run FastQC for the R2 (reverse-read) file:\n\n``` bash\nfastqc --outdir results/fastqc data/fastq/NW102AB_R2.fastq.gz\n```\n``` bash-out\nStarted analysis of NW102AB_R2.fastq.gz\nApprox 5% complete for NW102AB_R2.fastq.gz\nApprox 10% complete for NW102AB_R2.fastq.gz\nApprox 15% complete for NW102AB_R2.fastq.gz\n[...truncated...]\nAnalysis complete for NW102AB_R2.fastq.gz\n```\n\n``` bash\nls -lh results/fastqc\n```\n``` bash-out\n-rw-r--r-- 1 jelmer PAS0471 241K Mar 13 14:50 NW102AB_R1_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 256K Mar 13 14:50 NW102AB_R1_fastqc.zip\n-rw-r--r-- 1 jelmer PAS0471 234K Mar 13 14:53 NW102AB_R2_fastqc.html\n-rw-r--r-- 1 jelmer PAS0471 244K Mar 13 14:53 NW102AB_R2_fastqc.zip\n```\n\nNow, we have four files: two for each of our preceding successful FastQC runs.\n\n</details>\n:::\n\n<br>\n\n## Running FastQC with a shell script\n\nInstead of running FastQC interactively, we'll want to write a script that runs FastQC.\nSpecifically, our script will deliberately run FastQC on **only one FASTQ file**.\n\nGenerally speaking, for CLI tools that you need to run many times because they are\nindependently run for each file or sample (a very common occurrence in bioinformatics),\nan alternative approach would be to write the script such that it will\n_process all files/samples in a single run_. That in turn can be accomplished by:\n\n- Looping over files/samples inside the script.\n- Simply passing many file names (or a glob with `*`) as arguments to a single\n  run of the command --- note that this can be done with _some_ programs, including FastQC.\n\nHowever, given that we have access to OSC's clusters,\nit will save -potentially _a lot of_- running time when we submit a separate batch job\nfor each FASTQ file.\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Arguments to the script\n\nThis approach of running the script for one FASTQ file at a time means that\nour script needs to **accept an argument** (with in this case a FASTQ file name),\nsomething we have practiced with in the previous session.\nSo instead of using a line like this in the script,\nin which the FASTQ file name (`data/fastq/NW102AB_R1.fastq.gz`) is \"hardcoded\"...\n\n```bash\nfastqc --outdir results/fastqc data/fastq/NW102AB_R1.fastq.gz\n```\n\n...we would use a variable for it --- for example:\n\n```bash\nfastqc --outdir results/fastqc \"$fastq_file\"\n```\n\nAnd while we're at it, we may also want to use a variable for the output dir,\nas that is another thing we may want to vary among runs of the program:\n\n```bash\nfastqc --outdir \"$outdir\" \"$fastq_file\"\n```\n\nOf course, these variables don't appear out of thin air completely ---\nin a basic script along these lines we would have to re-assign the placeholder variables:\n  \n```bash\n# Copy the placeholder variables\nfastq_file=$1\noutdir=$2\n\n# Run FastQC\nfastqc --outdir \"$outdir\" \"$fastq_file\"\n```\n\nAnd such as script would be run for a single sample as follows:\n\n```bash\nbash scripts/fastqc.sh data/fastq/NW102AB_R1.fastq.gz results/fastqc\n```\n\nAnd by looping over all files as follows:\n\n```bash\nfor fastq_file in data/fastq/*fastq.gz; do\n    bash scripts/fastqc.sh \"$fastq_file\" results/fastqc\ndone\n```\n\nHowever, note that the above would run FastQC sequentially for each file,\njust like it would if the loop was in our script!\n\nTo get the promised running-time benefits,\nwe'd have to submit it as a batch job to OSC's Slurm queue.\nWe'll get into the details of doing this next week, but the main think we would need to do\nis replacing `bash` by `sbatch`, which is the Slurm command to submit a batch job:\n\n```bash\nfor fastq_file in data/fastq/*fastq.gz; do\n    sbatch scripts/fastqc.sh \"$fastq_file\" results/fastqc\ndone\n```\n\n<hr style=\"height:1pt; visibility:hidden;\" />\n\n### Touching up the script\n\nWe should add a few things to this script to e.g. make it run it smoothly as a\nbatch job at OSC:\n\n- The shebang line and the strict Bash settings:\n\n  ```bash\n  #!/bin/bash\n  \n  set -euo pipefail\n  ```\n\n- A line to load the relevant OSC software module:\n\n  ```bash\n  module load fastqc/0.11.8\n  ```\n  \n- Several `echo` statements to report what's going on (see below)\n- A line to create the output directory if it doesn't yet exist:\n\n  ```bash\n  mkdir -p \"$outdir\"\n  ```\n\n:::{.callout-tip collapse=\"true\"}\n## Refresher: the `-p` option to `mkdir` _(Click to expand)_\n\nUsing the `-p` option does two things at once,\nand both are necessary for a foolproof inclusion of this command in a script:\n\n- It will enable `mkdir` to create multiple levels of directories at once\n  (i.e., to act _recursively_):\n  by default, `mkdir` errors out if the parent directory/ies of the\n  specified directory don't yet exist.\n\n  ```bash\n  mkdir newdir1/newdir2\n  ```\n  ```{.bash-out}\n  mkdir: cannot create directory â€˜newdir1/newdir2â€™: No such file or directory\n  ```\n\n  ```bash\n  # This successfully creates both directories\n  mkdir -p newdir1/newdir2\n  ```\n\n- If the directory already exists, it won't do anything and won't return an error.\n  Without this option, `mkdir` would return an error in this case,\n  which would in turn lead the script to abort at that point with our `set` settings:\n  \n  ```bash\n  mkdir newdir1/newdir2\n  ```\n  ```{.bash-out}\n  mkdir: cannot create directory â€˜newdir1/newdir2â€™: File exists\n  ```\n\n  ```bash\n  # This does nothing since the dirs already exist\n  mkdir -p newdir1/newdir2\n  ```\n:::\n\nHere is what our script looks like with those additions:\n\n\n```{bash}\n#!/bin/bash\n#SBATCH --account=PAS2250\n#SBATCH --mail-type=FAIL\n#SBATCH --output=slurm-fastqc-%j.out\n  \n# Strict Bash settings\nset -euo pipefail\n\n# Load the OSC module for FastQC\nmodule load fastqc\n\n# Copy the placeholder variables\nfastq_file=\"$1\"\noutdir=\"$2\" \n\n# Initial reporting\necho \"# Starting script fastqc.ch\"\ndate\necho \"# Input FASTQ file:   $fastq_file\"\necho \"# Output dir:         $outdir\"\necho\n\n# Create the output dir if needed\nmkdir -p \"$outdir\"\n\n# Run FastQC\nfastqc --outdir=\"$outdir\" \"$fastq_file\"\n\n# Final reporting\necho\necho \"# Listing the output files:\"\nls -lh \"$outdir\"\n\necho\necho \"# Done with script fastqc.sh\"\ndate\n\n# (Don't run this in your terminal, but copy it into a .sh text file)\n```\n\n\n{{< fa user-edit >}} Open a new file in VS Code\n(&nbsp; {{< fa bars >}} &nbsp; => &nbsp; `File` &nbsp; => &nbsp; `New File`)\nand save it as `fastqc.sh` within your `scripts/` directory.\nPaste in the code above and save the file.\n\nNotice that this script is very similar to our toy scripts from the previous\nsessions:\nmostly standard (\"boilerplate\") code with\n**just a single command to run our program of interest.**\nTherefore, you can adopt this script as a template for scripts that run other\ncommand-line programs, and will generally only need minor modifications!\n\n:::{.exercise}\n### On Your Own: Use multiple threads {-}\n\nMost bioinformatics programs, including _FastQC_,\ncan make use of multiple threads/CPUs/cores\n(which we can all treat as the same unit below the node level, for our purposes),\nand this can speed things up tremendously.\n\nTo run FastQC with multiple threads, we need to take two steps &mdash;\nbelow, `n` is the number of threads that we would like to use.\n\n- Add the `#SBATCH --cpus-per-task=n` option to the script.\n\n- Tell _FastQC_ that it can use `n` threads.\n\n**Include both of these options in your `fastqc.sh` script so as to run _FastQC_**\n**with 8 cores.**\n\n(To find out the name of the _FastQC_ option for the number of threads,\nrun `fastqc --help` and search for the relevant option.)\n\n<details><summary>Hint (click here)</summary>\n\nThe _FastQC_ option in question is `-t` (short form) or `--threads` (long form).\nFor clarity, I would suggest to use the long form option in your script.\n\n</details>\n\n<details><summary>Solution (click here)</summary>\n\n- You should add the following `#SBATCH` line at the top of the script:\n\n```bash\n#SBATCH --cpus-per-task=8\n```\n\n- Your _FastQC_ command in the script should now be as follows\n  (though the order of the `--threads` and `--outdir` options does not matter,\n  as long as the input file positional argument comes last):\n\n```bash\nfastqc --threads 8 --outdir \"$outdir\" \"$fastq_file\"\n```\n\n</details>\n\n:::\n\n<br>\n\n## A master / runner \"script\"\n\nAbove, we created a `fastqc.sh` script,\nwhich we'll eventually want to submit a bunch of times with a `for` loop.\nThe code with that loop and the `sbatch` command _could_ be directly typed in the terminal.\n**But it's better to save the commands used for job submission in a file/script as well.**\n\nWe will now create such a file,\nwhich has the overall purpose of documenting the steps we took\nand the batch jobs we submitted.\n_You can think of this file as your analysis lab notebook,_\n_or perhaps more accurately,_\n_your notebook entry that contains the final protocol you followed._\n\nThis kind of script is sometimes called a \"master\" or \"runner\" script.\nBecause it will contain shell code, we will save it as a shell script (`.sh`)\njust like the script to run `fastqc.sh` and other individual analysis steps.\n**However, it is important to realize that the runner script is conceptually different**\n**from the scripts that run individual steps of your analysis.**\nThe latter are meant to be run/submitted in their entirety by the runner script,\nwhereas a basic runner script that contains `sbatch` compute job commands for\nmultiple steps has to be run step-by-step (see the box below).\n\n::: {.callout-warning collapse=\"true\"}\n#### The runner script can't itself be run at once in its entirety (Click to expand)\nOnce we've added multiple batch job steps,\nand the input of a later step uses the output of an earlier step,\nwe won't be able to just _run_ the script as is.\n**This is because the runner script would then submit jobs from different steps**\n**all at once,**\n**and that later step would start running before the earlier step has finished.**\n\nFor example, consider the following series of two steps,\nin which the second step uses the output of the first step: \n\n```bash\n# This script would create a genome \"index\" for STAR, that will be used in the next step\n# ('my_genome.fa' = input genome FASTA, 'results/star_index' = output index dir)\nsbatch scripts/star_index.sh my_genome.fa results/star_index\n\n# This script would align a FASTQ file to the genome index created in the previous step\n# ('results/star_index' = input index dir, 'sampleA.fastq.gz' = input FASTQ file,\n# 'results/star_align' = output dir)\nsbatch scripts/star_align.sh results/star_index sampleA.fastq.gz results/star_align \n```\n\nIf these two lines were included in your runner script,\nand you would run that script in its entirety all at once,\nthe script in the second step would be submitted just a split-second after the\nfirst one\n(recall: when using `sbatch`, you get your prompt back immediately -- there is no waiting).\nAs such, it would fail because of the missing output from the first step.\n\nIt _is_ possible to make `sbatch` batch jobs wait for earlier steps to finish\n(e.g. with the `--dependency` option), but this quickly gets tricky.\nIf you want to create a workflow/pipeline that can run from start to finish in\nan automated way, \nyou should consider using a workflow management system\nlike [Snakemake](https://snakemake.readthedocs.io/en/stable/) or\n[NextFlow](https://www.nextflow.io/).\n\n:::\n\nTo summarize, we'll **separate our code into two hierarchical levels of scripts**,\nwhich we'll also save in separate dirs to make this division clear:\n\n- The scripts that run _individual steps of your analysis_, like `fastqc.sh`.\n  We'll save these in a directory called `scripts`.\n- An _overarching \"runner\" script_ that orchestrates the batch job submission\n  of these individual steps.\n  We'll save this script in a directory called `run`.\n\n{{< fa user-edit >}} Let's go ahead and open a new text file,\nand save it as `run/run.sh`\n(_VS Code_ should create that directory on the fly as needed).\n\n::: {.callout-tip}\n#### Keep the scripts for individual steps simple\nIt is a good idea to keep the shell scripts you will submit (e.g., `fastqc.sh`) simple\n_in the sense that they should generally just run one program_,\nand not a sequence of programs.\n\nOnce you get the hang of writing these scripts,\nit may seem appealing to string a series of programs/steps together in a single script,\nso that it's easier to rerun everything at once &mdash;\nbut in practice, that will often end up leading to more difficulties than convenience.\nOnce again, if you do want to develop a workflow that can run from start to finish,\nyou'll have to bite the bullet and learn a workflow management system like\nSnakemake or Nextflow.\n:::\n\n<br>\n\n## Looping over samples rather than files \n\nIn our script, we will run Cutadapt inside a loop, similar to how we ran FastQC.\nHowever, this case is a bit more complicated, because we need to run Cutadapt\nfor one **sample** and therefore two FASTQ files at a time,\nrather than for one FASTQ file at a time.\n\nWe will do that by **looping over the R1 (forward read) files only**,\nand inside the loop, inferring the name of the R2 file:\n\n```bash\n# (Don't run this - this will be part of our script)\n\n# Loop over the R1 files\nfor R1_in in data/fastq/*R1.fastq.gz; do\n    # Get the R2 file name with \"parameter expansion\"\n    # This does a search-and-replace: replace \"_R1\" with \"_R2\"\n    R2_in=${R1_in/_R1/_R2}\n    \n    # Report\n    echo \"Input files: $R1_in $R2_in\"\n    \n    # Define the output files\n    R1_out=\"$outdir\"/$(basename \"$R1_in\")\n    R2_out=\"$outdir\"/$(basename \"$R2_in\")\n    \n    # Run Cutadapt\n    cutadapt \\\n            -a \"$primer_f\"...\"$primer_r_rc\" \\\n            -A \"$primer_r\"...\"$primer_f_rc\" \\\n            --trimmed-only \\\n            --cores 8 \\\n            --output \"$R1_out\" \\\n            --paired-output \"$R2_out\" \\\n            \"$R1_in\" \"$R2_in\"\ndone\n```\n\n<br>\n\n",
    "supporting": [
      "w4_3_cli-tools_files"
    ],
    "filters": [],
    "includes": {}
  }
}